# **00.SPEC_FRAMEWORK.md**

**Version:** 3.0.0
**Last Updated:** 2025-11-09
**Status:** Stable

---

**ðŸ“‹ How to Use This File:**

This is the **framework definition** â€” the single seed file you need. Copy this file to your project as a reference document. AI assistants will read the examples and guidance in this document to generate your actual specification files (01-05).

**Framework Repository** (this repo) contains:
- `00.SPEC_FRAMEWORK.md` â† This file (copy to your project)
- `README.md`, `CLAUDE.md`, `CHANGELOG.md` (documentation)

**Your Project** (after using this framework) will contain:
- `00.SPEC_FRAMEWORK.md` (copied reference)
- `01.FOUNDATIONAL_PHILOSOPHY.md` (your Level 1 spec, generated by AI)
- `02.STABLE_TRUTHS.md` (your Level 2 spec)
- `03.INTERACTION_ARCHITECTURE.md` (your Level 3 spec)
- `04.SYSTEMS/` (your Level 4 specs)
- `05.IMPLEMENTATION/` (your Level 5 specs)

---

## Overview

This document defines a hierarchical specification system enforcing **dependency inversion**: foundational philosophy guides implementation, never vice versa. High-level policy sets direction; low-level details cascade downward.

**Core principle:** Each concern lives at exactly one level (single source of truth). Changes flow downward through abstraction layers while foundational documents remain stable.

> **See [CHANGELOG.md](CHANGELOG.md) for version history and migration guides.**

## The Five-Level Hierarchy

### Quick Reference

| Level | Icon | Purpose | Key Question | Audience | References |
|-------|------|---------|--------------|----------|------------|
| **1: Foundational Philosophy** | ðŸ“˜ | WHY & WHAT EXPERIENCE | "What problem must we solve? What should users feel?" | Founders, designers, domain experts | External only |
| **2: Stable Truths** | âš™ï¸ | Design strategies & commitments | "What approach will we take?" | System designers, product strategists | L1 + External |
| **3: Interaction Architecture** | ðŸ”„ | HOW users and product interact | "What's the behavioral pattern?" | Interaction designers, developers | L1-2 + External |
| **4: Systems** | ðŸ§© | Implementation architecture | "How do we build this?" | Developers, AI systems, implementers | L1-3 + Sibling L4 + External |
| **5: Implementation** | âš–ï¸ | Validation & numeric tuning | "Does it work? What values?" | PMs, QA, data scientists | All levels + External |

### Level Details

#### ðŸ“˜ **Level 1: Foundational Philosophy** â€” WHY & WHAT EXPERIENCE

**Purpose:** Philosophical, psychological, and experiential foundations that should _never_ change. Defines both why the product exists and what core experiences it creates.

**Key Contents:**
- Mission statement ("Why this product must exist")
- **Design Pillars** (3-5 core experiences/emotions that define the product)
- Inviolable principles
- North-star experience

**Design Pillars:** Short, emotional phrases (1 sentence max) that capture the essence of the user experience. These serve as decision filtersâ€”features must support at least one pillar. Focus on how users will FEEL, not what they will do.

**Reference Rules:** External resources only. Cannot reference any project documents. Use placeholders for numbers.

**Example:**
```markdown
## Mission
Transform how people interact with [domain] by prioritizing [core value] over [traditional approach].

## Design Pillars

### 1. Empowered Action
Users feel in control and capable, never overwhelmed or helpless.

**User perspective:** "I feel confident I can accomplish what I set out to do."

**Examples:**
- Clear pathways to goals with visible progress
- Gentle guidance without forced behavior

### 2. Sustainable Engagement
Users experience energizing focus, not draining obligation.

**User perspective:** "I feel refreshed and motivated, not burned out."

**Examples:**
- Rewards for effort without punishment for breaks
- Natural stopping points that respect user time

## Inviolable Principles
- Never sacrifice [value] for [competing concern]
- Always prioritize [key constraint]
- No guilt-inducing mechanics (supports Sustainable Engagement pillar)
```

---

#### âš™ï¸ **Level 2: Stable Truths** â€” WHAT Strategy

**Purpose:** Philosophically committed choices about how the product works.

**Key Contents:**
- Design philosophies
- Architectural commitments and patterns
- Definition of "success"
- Constraints and trade-offs

**Reference Rules:** Can reference Level 1 + external. Cannot reference L3-5. Use placeholders for numbers.

**Example:**
```markdown
### Truth: Complexity must be emergent, not imposed
The system should have simple rules that combine to create rich behavior, rather than complex rules that create rigid experiences.
```

---

#### ðŸ”„ **Level 3: Interaction Architecture** â€” HOW (Conceptual)

**Purpose:** Fundamental patterns of user-product interaction before implementation.

**Key Contents:**
- Core interaction loops and patterns
- User behavior models
- Multi-scale architecture (immediate, session, extended, lifetime)
- Edge cases and failure modes
- Verification criteria

**Reference Rules:** Can reference L1-2 + external. Cannot reference L4-5. Use placeholders for numbers.

**Example:**
```markdown
## Interaction Loop Architecture
| Scale     | Scope                | Duration   | Key Systems         |
|-----------|----------------------|------------|---------------------|
| Immediate | Single action        | Seconds    | Input, Feedback     |
| Session   | Connected actions    | Minutes    | State, Progress     |
| Extended  | Across sessions      | Days/Weeks | Persistence, Growth |
| Lifetime  | Product relationship | Ongoing    | Learning, Evolution |
```

---

#### ðŸ§© **Level 4: Systems** â€” HOW (Implementation)

**Purpose:** Design documents for the "physics" of the product.

**Key Contents:**
- System boundaries and responsibilities
- Data structures and attributes
- Rules and algorithms (conceptual, not code)
- System interactions and interfaces
- State management

**Reference Rules:** Can reference L1-3 + sibling L4 docs + external. Cannot reference L5. Use placeholders for numbers.

**Suggested Structure:**
- `SYSTEMS_OVERVIEW.md` â€” System interconnections
- `[DOMAIN]_SYSTEM.md` â€” One per major subsystem

**Example:**
```markdown
## Entity Properties
- id (uuid), name (string), created_at (timestamp)
- status (enum: active, inactive, archived)
- metadata (key-value map)

## State Transitions
Entity moves from `active` to `inactive` when [condition].
Entity can only be `archived` if `inactive` for [duration].
```

---

#### âš–ï¸ **Level 5: Implementation** â€” Validation & Tuning

**Purpose:** Validate systems through user stories and tune with numeric parameters.

**Key Contents:**
- **User Stories** â€” Validation from user perspective
  - Organized by priority/journey/system
  - Acceptance criteria + system references
  - Cross-cutting (spans multiple L4 systems)
- **Fine Tuning** â€” Numeric balancing
  - Constants, timing, scaling factors
  - Rationale for each value
  - A/B test configurations

**Reference Rules:** Can reference ALL levels (1-4) + external. Only level that defines actual numeric values.

**Example User Story (YAML with Cypress Test DSL):**
```yaml
# @priority: MVP
# @systems: [TASK_SYSTEM, REWARD_SYSTEM]

id: US-102
title: See points awarded immediately on task completion

acceptance_criteria:
  - id: AC-102-1
    title: Points update within 100ms
    narrative: |
      Given I have an active task
      When I complete the task
      Then I see points increase within 100ms
    given:
      - loginAs: member
      - seedItem: { slug: 'my-task', status: 'active' }
      - visit: '/tasks/my-task'
    when:
      - click: { selector: '[data-test=complete-task]' }
    then:
      - shouldContain: { selector: '[data-test=points]', text: '10' }
```

**Example Fine Tuning:**
```yaml
# =============================================================================
# LEVEL 5: FINE TUNING - Interaction Timing
# =============================================================================
# @spec_version: 1.0.0
# @system: INTERACTION_TIMING
# @last_updated: 2024-01-15T14:30:00Z
# @status: production
# @spec_source: 03.INTERACTION_ARCHITECTURE.md

# All timing values in milliseconds

feedback:
  delay: 200
  # @rationale: Fast enough to feel immediate, slow enough to be noticeable
  # @reference: Nielsen Norman Group - Response Times: The 3 Important Limits
  # @constraints: min=50, max=500, type=integer

transitions:
  duration: 300
  # @rationale: Standard ease-out timing for smooth UI transitions
  # @alternatives: [200, 300, 500]
  # @test_result: 300ms rated highest for perceived smoothness (n=100)

timeouts:
  threshold: 30000
  # @rationale: Balance between patience and abandonment
  # @reference: UX research shows 30s is typical user patience limit
  # @constraints: min=5000, max=60000, type=integer
```

---

## ðŸ“ Document Reference Hierarchy

**CRITICAL RULE:** Each level can only reference higher levels, never lower ones.

### Reference Matrix

| Level                                  | Can Reference                                |
| -------------------------------------- | -------------------------------------------- |
| **Level 1** (Foundational Philosophy)  | External resources only                      |
| **Level 2** (Stable Truths)            | Level 1 + External                           |
| **Level 3** (Interaction Architecture) | Levels 1-2 + External                        |
| **Level 4** (Systems)                  | Levels 1-3 + Sibling Level 4 docs + External |
| **Level 5** (Implementation)           | All levels (1-4) + External                  |

### Enforcement Rules

**NEVER reference lower levels from higher levels.**

âœ— **Violations:**

- Level 3 referencing specific system implementations from Level 4
- Level 4 referencing numeric values from Level 5
- Level 2 referencing interaction patterns from Level 3

âœ“ **Correct:**

- Level 2 referencing philosophical constraints from Level 1
- Level 4 referencing interaction principles from Level 3
- Level 5 referencing any level to understand context for tuning

### Why This Matters

This ensures:

- **Foundational documents remain stable** â€” Philosophy doesn't change when you adjust numbers
- **Changes flow downward** â€” Implementation evolves without corrupting principles
- **Architectural integrity** â€” High-level decisions guide low-level details, not vice versa
- **Separation of concerns** â€” What vs Why vs How vs How Much live at appropriate levels

---

## ðŸ“ User Project Directory Structure

When you create a specification using this framework, your project directory will contain:

```
/
â”œâ”€â”€ 00.SPEC_FRAMEWORK.md               # Framework definition (copied reference)
â”œâ”€â”€ 01.FOUNDATIONAL_PHILOSOPHY.md      # Your Level 1 spec (WHY & WHAT EXPERIENCE)
â”œâ”€â”€ 02.STABLE_TRUTHS.md                # Design philosophy and commitments
â”œâ”€â”€ 03.INTERACTION_ARCHITECTURE.md     # How users and product interact
â”œâ”€â”€ 04.SYSTEMS/                        # Implementation architecture
â”‚   â”œâ”€â”€ SYSTEMS_OVERVIEW.md           # How systems interconnect
â”‚   â”œâ”€â”€ [SYSTEM_A].md                 # First major subsystem
â”‚   â”œâ”€â”€ [SYSTEM_B].md                 # Second major subsystem
â”‚   â””â”€â”€ [SYSTEM_N].md                 # Additional subsystems
â””â”€â”€ 05.IMPLEMENTATION/                # Validation and tuning
    â”œâ”€â”€ USER_STORIES/                 # User perspective validation (YAML with Cypress tests)
    â”‚   â”œâ”€â”€ USER_STORIES_OVERVIEW.md  # Organization and test generation docs
    â”‚   â”œâ”€â”€ by_priority/              # Organized by development phase
    â”‚   â”‚   â”œâ”€â”€ MVP.yaml              # MVP stories (auto-generates Cypress tests)
    â”‚   â”‚   â”œâ”€â”€ SECONDARY.yaml        # Enhanced experience stories
    â”‚   â”‚   â””â”€â”€ ADVANCED.yaml         # Future feature stories
    â”‚   â”œâ”€â”€ by_journey/               # Organized by user flow
    â”‚   â”‚   â”œâ”€â”€ [JOURNEY_A].yaml      # First user journey
    â”‚   â”‚   â””â”€â”€ [JOURNEY_B].yaml      # Second user journey
    â”‚   â””â”€â”€ by_system/                # Organized by system
    â”‚       â”œâ”€â”€ [SYSTEM_A].yaml       # Stories for System A
    â”‚       â””â”€â”€ [SYSTEM_B].yaml       # Stories for System B
    â””â”€â”€ FINE_TUNING/                  # Numeric balancing (comment-annotated YAML)
        â”œâ”€â”€ [SYSTEM_A].yml            # Parameters for System A
        â”œâ”€â”€ [SYSTEM_B].yml            # Parameters for System B
        â””â”€â”€ [PARAMETERS_N].yml        # Additional parameter sets
```

---

## Usage Guidelines

### When Creating New Documents

1. **Determine the correct level** â€” Ask: "Is this about WHY, WHAT strategy, HOW it works conceptually, HOW it's implemented, or HOW MUCH?"
2. **Check reference constraints** â€” Ensure you only reference appropriate levels
3. **Use placeholders** â€” In Levels 1-4, use descriptive placeholders like `[short duration]` instead of `200ms`
4. **Maintain abstraction** â€” Each level should be complete without depending on lower levels

### Organizing User Stories at Level 5

User stories belong at **Level 5** (Implementation), where they validate system implementations from the user's perspective and automatically generate Cypress tests. User stories are written in **YAML format** with structured acceptance criteria that map directly to executable test specifications.

**Why Level 5?**

- User stories validate that systems deliver the intended user experience
- They bridge the gap between system specifications (Level 4) and actual implementation
- They're cross-cutting by nature, often spanning multiple systems
- They provide executable acceptance criteria through auto-generated Cypress tests
- They maintain traceability from user intent to test validation

**Core principles:**

- Stories focus on **user outcomes** while providing **testable specifications**
- Stories tell **what** and **why** through narrative, **how to test** through DSL steps
- Acceptance criteria define **observable behaviors** in machine-parseable format
- Stories should be specific enough to implement and test unambiguously
- Stories can reference multiple Level 4 systems (cross-cutting)
- Include system references to link back to architectural specs

**Organization structure:**

User stories are organized in YAML files across multiple views to support different perspectives:

1. **by_priority/** â€” Groups stories by development phase (MVP, Secondary, Advanced)

   - Helps prioritize implementation efforts
   - Aligns with product roadmap and release planning
   - Each file generates its own test suite

2. **by_journey/** â€” Groups stories by user flow (e.g., Onboarding, Daily Usage)

   - Validates complete user experiences end-to-end
   - Ensures coherent user journeys across systems
   - Each journey file generates journey-specific tests

3. **by_system/** â€” Groups stories by primary system referenced
   - Links validation back to system architecture
   - Helps verify each system delivers user value
   - Each system file generates system-specific tests

Stories can appear in multiple organizational views to enable different test perspectives.

**YAML Format with Test DSL:**

User stories use comment-annotated YAML format similar to FINE_TUNING files:

```yaml
# =============================================================================
# USER STORY: [Story Title]
# =============================================================================
# @spec_version: 1.0.0
# @priority: MVP | SECONDARY | ADVANCED
# @journey: [JOURNEY_NAME]
# @systems: [SYSTEM_A, SYSTEM_B]
# @last_updated: [ISO 8601 timestamp]

id: US-101
title: [Story title]
requirement_id: R-101  # Optional reference to requirements

acceptance_criteria:
  - id: AC-101-1
    title: [Acceptance criteria title]
    narrative: |
      Given [context]
      When [action]
      Then [expected outcome]

    # Test DSL: Given-When-Then structure
    given:
      - [setup steps]
    when:
      - [action step]
    then:
      - [assertion steps]
```

**Core Test DSL Steps:**

The framework provides a core set of test steps that can be extended with domain-specific steps:

**Setup Steps (given/when):**
- `visit: '/path'` - Navigate to a path
- `click: { selector: '[data-test=button]' }` - Click an element
- `fill: { selector: '[data-test=input]', value: 'text' }` - Fill an input
- `loginAs: 'user_role'` - Authenticate as a user type
- `seedItem: { slug: 'item-id', status: 'available' }` - Seed test data

**Assertion Steps (then):**
- `shouldContain: { selector: '[data-test=element]', text: 'expected' }` - Verify text content
- `shouldExist: { selector: '[data-test=element]' }` - Verify element exists

**Extending the DSL:**

Projects should extend the core DSL with domain-specific steps in `templates/cypress/support/steps.ts`:

```typescript
// Add custom step types to the Step union
export type Step =
  | { visit: string }
  | { click: { selector: string } }
  // ... core steps ...
  | { createProject: { name: string } }  // Custom step
  | { inviteUser: { email: string, role: string } }  // Custom step

// Implement custom steps in runSetupSteps
export function runSetupSteps(steps: Step[]) {
  for (const s of steps ?? []) {
    if ('visit' in s) cy.visit(s.visit);
    // ... other steps ...
    else if ('createProject' in s) {
      cy.task('createProject', s.createProject);
    }
    else if ('inviteUser' in s) {
      cy.task('inviteUser', s.inviteUser);
    }
  }
}
```

**Example User Story:**

```yaml
# =============================================================================
# USER STORY: Quick Task Creation
# =============================================================================
# @spec_version: 1.0.0
# @priority: MVP
# @journey: DAILY_USAGE
# @systems: [TASK_SYSTEM]
# @last_updated: 2025-11-09T00:00:00Z

id: US-101
title: Add new tasks quickly
requirement_id: R-101

acceptance_criteria:
  - id: AC-101-1
    title: Member can create task from main screen
    narrative: |
      Given I am a logged-in member viewing the main screen
      When I click the add task button and enter a task name
      Then I should see the task appear in my current list
    given:
      - loginAs: member
      - visit: '/dashboard'
    when:
      - click: { selector: '[data-test=add-task]' }
      - fill: { selector: '[data-test=task-input]', value: 'Buy groceries' }
      - click: { selector: '[data-test=save-task]' }
    then:
      - shouldExist: { selector: '[data-test=task-list] [data-test=task-item]' }
      - shouldContain: { selector: '[data-test=task-item]', text: 'Buy groceries' }

  - id: AC-101-2
    title: Empty tasks are rejected
    narrative: |
      Given I am a logged-in member viewing the main screen
      When I try to create a task with only whitespace
      Then I should see a validation error and no task is created
    given:
      - loginAs: member
      - visit: '/dashboard'
    when:
      - click: { selector: '[data-test=add-task]' }
      - fill: { selector: '[data-test=task-input]', value: '   ' }
      - click: { selector: '[data-test=save-task]' }
    then:
      - shouldContain: { selector: '[data-test=error]', text: 'Task name is required' }
      - shouldExist: { selector: '[data-test=task-list]:empty' }
```

**Cross-System Example:**

```yaml
# =============================================================================
# USER STORY: Instant Reward Feedback
# =============================================================================
# @spec_version: 1.0.0
# @priority: MVP
# @journey: DAILY_USAGE
# @systems: [TASK_SYSTEM, REWARD_SYSTEM, VIEW_SYSTEM]
# @last_updated: 2025-11-09T00:00:00Z

id: US-102
title: See points awarded immediately on task completion
requirement_id: R-102

acceptance_criteria:
  - id: AC-102-1
    title: Points update within 100ms of completion
    narrative: |
      Given I have an active task with base points value
      When I mark the task as complete
      Then I should see my points total increase within 100ms
    given:
      - loginAs: member
      - seedItem: { slug: 'my-task', status: 'active', points: 10 }
      - visit: '/tasks/my-task'
    when:
      - click: { selector: '[data-test=complete-task]' }
    then:
      - shouldContain: { selector: '[data-test=points-total]', text: '10' }
      - shouldExist: { selector: '[data-test=feedback-animation]' }
```

**Runtime Test Generation:**

User story YAML files are automatically transformed into Cypress tests at runtime:

- **Schema validation:** `templates/cypress/support/schema.ts` validates YAML structure
- **DSL interpretation:** `templates/cypress/support/steps.ts` converts DSL to Cypress commands
- **Test generation:** `templates/cypress/e2e/*.cy.ts` dynamically creates test suites

**Directory Structure:**

```
05.IMPLEMENTATION/
â””â”€â”€ USER_STORIES/
    â”œâ”€â”€ USER_STORIES_OVERVIEW.md     # Organization and test generation docs
    â”œâ”€â”€ by_priority/
    â”‚   â”œâ”€â”€ MVP.yaml                 # MVP user stories â†’ cypress/e2e/by_priority.cy.ts
    â”‚   â”œâ”€â”€ SECONDARY.yaml           # Secondary features
    â”‚   â””â”€â”€ ADVANCED.yaml            # Advanced features
    â”œâ”€â”€ by_journey/
    â”‚   â”œâ”€â”€ ONBOARDING.yaml          # Onboarding journey â†’ cypress/e2e/by_journey.cy.ts
    â”‚   â””â”€â”€ DAILY_USAGE.yaml         # Daily usage journey
    â””â”€â”€ by_system/
        â”œâ”€â”€ TASK_SYSTEM.yaml         # Task system stories â†’ cypress/e2e/by_system.cy.ts
        â””â”€â”€ REWARD_SYSTEM.yaml       # Reward system stories
```

**Benefits of YAML + Cypress Approach:**

- **Single source of truth:** User stories ARE the test specification
- **Living documentation:** Tests always match documented user stories
- **Traceability:** Clear path from L4 systems â†’ L5 stories â†’ Cypress tests
- **Version control:** YAML stories track changes with full context
- **AI-friendly:** Structured format for AI-assisted story/test generation
- **Multi-view testing:** Same stories generate priority, journey, and system test suites

---

### Fine Tuning YAML Format and Conventions

Fine tuning parameters at Level 5 use **comment-annotated YAML** format. This approach keeps the YAML structure clean (containing only actual values) while embedding rich metadata and rationale in comments.

**Core Principles:**

1. **Values are first-class** â€” The YAML structure contains only deployable configuration values
2. **Metadata in comments** â€” All annotations, rationale, and context use comment syntax
3. **Machine-parseable** â€” Strip comments to get clean config; parse comments for documentation
4. **Human-readable** â€” Rich context without cluttering the data structure
5. **Traceable** â€” Every value links back to spec levels and decisions

**Comment Annotation Syntax:**

Use `# @annotation: value` format for structured metadata:

```yaml
# =============================================================================
# LEVEL 5: FINE TUNING - [System Name]
# =============================================================================
# @spec_version: [version]
# @system: [SYSTEM_NAME]
# @last_updated: [ISO 8601 timestamp]
# @status: draft | testing | production | deprecated
# @spec_source: [reference to L1-4 docs]

# Section description (free-form comment)
# @spec_source: [specific doc reference for this section]

parameter_name: value
# @rationale: Why this specific value was chosen
# @reference: External research, papers, or documentation
# @alternatives: [other values considered]
# @test_result: Supporting data from testing
# @constraints: min=X, max=Y, type=Z
# @inviolable: true (if from L1, cannot be changed)
# @review_date: When to revisit this value
# @impact: [affected systems]
```

**Standard Annotation Tags:**

| Tag | Purpose | Example |
|-----|---------|---------|
| `@spec_version` | Version of spec this implements | `@spec_version: 1.0.0` |
| `@system` | Which L4 system this configures | `@system: REWARD_SYSTEM` |
| `@last_updated` | ISO 8601 timestamp | `@last_updated: 2024-01-15T14:30:00Z` |
| `@status` | Current status | `@status: production` |
| `@spec_source` | Reference to spec docs | `@spec_source: 04.SYSTEMS/REWARD_SYSTEM.md:45` |
| `@rationale` | Why this value | `@rationale: Testing showed optimal engagement` |
| `@reference` | External sources | `@reference: Nielsen Norman Group - Response Times` |
| `@alternatives` | Other values tested | `@alternatives: [5, 10, 20]` |
| `@test_result` | Supporting data | `@test_result: 82% engagement (n=100)` |
| `@constraints` | Validation rules | `@constraints: min=1, max=100, type=integer` |
| `@inviolable` | Cannot change (L1) | `@inviolable: true` |
| `@review_date` | When to revisit | `@review_date: 2024-04-15` |
| `@impact` | Affected systems | `@impact: [REWARD_SYSTEM, PROGRESS_SYSTEM]` |
| `@ab_test` | Experiment config | `@ab_test: variants=[0.05, 0.07, 0.10], duration=4w` |
| `@ethical_review` | Ethical considerations | `@ethical_review: Approved 2024-01-08, see ethics doc` |

**Complete Example:**

```yaml
# =============================================================================
# LEVEL 5: FINE TUNING - Reward System
# =============================================================================
# @spec_version: 1.0.0
# @system: REWARD_SYSTEM
# @last_updated: 2024-01-15T14:30:00Z
# @status: production
# @spec_source: 04.SYSTEMS/REWARD_SYSTEM.md

# -----------------------------------------------------------------------------
# Point Calculation
# -----------------------------------------------------------------------------
# @spec_source: 04.SYSTEMS/REWARD_SYSTEM.md:45

points:
  base: 10
  # @rationale: After testing with 100 users over 2 weeks:
  #   - 5 points: felt insignificant, engagement dropped 23%
  #   - 10 points: "just right", engagement peaked at 82%
  #   - 20 points: felt cheap, users hit 1000pts in 3 days
  # @test_result: engagement_score=8.7/10 (n=100, 2024-01-10)
  # @alternatives: [5, 15, 20, 25]
  # @constraints: min=1, max=100, type=integer
  # @review_date: 2024-04-15
  # @impact: [REWARD_SYSTEM, PROGRESS_SYSTEM, ACHIEVEMENT_SYSTEM]

  difficulty_multipliers:
    easy: 1.0
    medium: 1.5
    hard: 2.0
    # @rationale: 50% increase per tier follows Weber-Fechner law of
    #   just-noticeable difference in human perception
    # @reference: https://en.wikipedia.org/wiki/Weber-Fechner_law
    # @spec_source: 04.SYSTEMS/REWARD_SYSTEM.md:52
    # @alternatives: linear=[10,15,20], exponential=[1.0,2.0,4.0]
    # @test_result: 50% intervals rated clearest (clarity=8.9/10, n=500)

# -----------------------------------------------------------------------------
# Variable Rewards (Bonus System)
# -----------------------------------------------------------------------------
# @spec_source: 02.STABLE_TRUTHS.md:78, 04.SYSTEMS/REWARD_SYSTEM.md:89

variable_rewards:
  probability: 0.07
  # @rationale: Variable ratio schedule from Skinner's research.
  #   7% = ~1 bonus per 14 completions, ~1 every 3-4 days for typical users
  # @reference: Skinner (1956) - operant conditioning research
  # @alternatives: [0.05, 0.07, 0.10]
  # @test_result: 0.05 too rare, 0.10 too predictable, 0.07 optimal
  # @ab_test: variants=[0.05, 0.07, 0.10], duration=4w, metric=retention
  # @ethical_review: Approved 2024-01-08 - transparent, no punishment, optional
  # @constraints: min=0.01, max=0.20, type=float

  multiplier:
    min: 1.5
    max: 3.0
    # @rationale: 1.5x minimum feels special, 3.0x max avoids game-breaking
    # @spec_source: 04.SYSTEMS/REWARD_SYSTEM.md:94
    # @alternatives: conservative=[1.2,2.0], aggressive=[2.0,5.0]
    # @test_result: [1.5,3.0] rated "exciting but fair" (n=50)
    # @constraints: min=1.1, max=5.0, type=float
    # @review_date: 2024-07-15

# -----------------------------------------------------------------------------
# Inviolable Constraints (from L1 Foundational Philosophy)
# -----------------------------------------------------------------------------
# @spec_source: 01.FOUNDATIONAL_PHILOSOPHY.md

streak:
  enabled: false
  # @inviolable: true
  # @rationale: L1 principle "Never create guilt" - no punishment for breaks
  # @spec_source: 01.FOUNDATIONAL_PHILOSOPHY.md:23
  # @note: Streak bonuses available in code but disabled per L1 philosophy
```

**Benefits:**

- **Clean YAML** â€” Strip comments â†’ deployable config
- **Rich documentation** â€” All context inline with values
- **Traceability** â€” Every value traces to spec decisions
- **Version control** â€” Git diffs show values + context changes
- **Validation** â€” `@constraints` enable automated validation
- **Tooling-friendly** â€” Parse `@annotations` for automation

**Tooling Recommendations:**

1. **Config Generator** â€” Strip all comments to produce clean deployment configs
2. **Documentation Generator** â€” Extract `@rationale` and `@reference` to create decision logs
3. **Validator** â€” Parse `@constraints` to validate values
4. **Traceability Tool** â€” Follow `@spec_source` back to architectural docs
5. **Change Impact Analyzer** â€” Use `@impact` to assess change ripple effects

### When Modifying Documents

1. **Start at the appropriate level** â€” If changing philosophy, start at Level 1; if tuning numbers, work in Level 5
2. **Propagate changes downward** â€” Update lower levels to align with changes in higher levels
3. **Never propagate upward** â€” Implementation details should never require changes to philosophy
4. **Verify references** â€” Ensure no new violations of the hierarchy rules

### When Reviewing Documents

- **Check for leaky abstractions** â€” Does a high-level doc reference implementation details?
- **Verify single source of truth** â€” Is each concept defined at exactly one level?
- **Confirm stability** â€” Could you completely reimplement Level 4 without touching Levels 1-3?

---

## Adaptation Guide

To adapt this framework to your project:

1. **Keep the 5-level structure** â€” The hierarchy has proven effective across diverse domains
2. **Rename Level 3 if needed** â€” "Interaction Architecture" works for many products, but you might use "Behavioral Architecture," "Information Architecture," "Flow Architecture," etc.
3. **Customize Level 4 subsystems** â€” Your systems will be specific to your domain
4. **Organize Level 5 appropriately** â€” Use USER_STORIES/ for validation and FINE_TUNING/ for parameters, or adapt the structure to your implementation needs
5. **Maintain reference rules** â€” This is the core constraint that makes the framework valuable
6. **Add a project-specific guide** â€” Consider creating a `CLAUDE.md` or similar to guide AI assistants on your specific terminology and conventions

---

## AI Assistant Guidance for Creating New Specs

### Overview

This section provides guidance for AI assistants helping product owners create specifications using this framework. The goal is to extract complete, well-structured information through strategic questioning while maintaining the hierarchical integrity of the spec system.

**Core Principles for AI Assistants:**

1. **Always start at Level 1** â€” Resist jumping to implementation details; understand the "why" first
2. **One level at a time** â€” Complete each level before descending to the next
3. **Ask "why" more than "what"** â€” Understanding intent prevents misaligned implementations
4. **Use concrete examples** â€” Request specific scenarios and user stories, not abstractions
5. **Validate hierarchy** â€” Continuously check that levels don't reference lower levels
6. **Challenge assumptions** â€” Question unstated dependencies and hidden implementation details
7. **Identify anti-patterns** â€” Help users avoid common specification mistakes

---

### Session Flow Recommendations

Effective spec creation typically follows this phased approach:

#### **Phase 1: Discovery â€” Level 1**

**Objective:** Extract the philosophical and emotional foundation

- Focus exclusively on WHY the product must exist
- Ask multiple rounds of clarifying questions
- Challenge the user's assumptions about problems and solutions
- Identify what the product will NOT do
- Define emotional goals and user promises
- Validate that principles are truly inviolable

**Key milestone:** Product owner can articulate the mission without mentioning features

---

#### **Phase 2: Strategy â€” Level 2**

**Objective:** Translate principles into design commitments

- Identify frameworks, paradigms, or existing patterns that apply
- Document architectural philosophies and why they were chosen
- Define success criteria and constraints
- Explore trade-offs and their justifications
- Identify what approaches are being rejected and why

**Key milestone:** Clear design philosophy that guides all subsequent decisions

---

#### **Phase 3: Architecture â€” Level 3**

**Objective:** Map the interaction model before implementation

- Walk through complete user journeys from trigger to outcome
- Identify all interaction loops and their scales (immediate, session, extended, lifetime)
- Document how different parts coordinate to create experiences
- Explore failure modes and edge cases
- Define verification criteria for implementations

**Key milestone:** Complete interaction architecture that could guide multiple different implementations

---

#### **Phase 4: Systems â€” Level 4**

**Objective:** Define system boundaries, data, and rules

- Break product into logical subsystems
- Define each system's responsibilities and boundaries
- Document data models with attributes and types
- Specify rules, algorithms, and state transitions (conceptually, not code)
- Map system interactions and dependencies
- Use placeholders for all numeric values

**Key milestone:** Complete system specifications that implementers can build from

---

#### **Phase 5: Validation â€” Level 5**

**Objective:** Create user stories and identify tuning parameters

- Generate user stories from the user's perspective
- Organize stories by priority (MVP/Secondary/Advanced), journey, and system
- Define observable acceptance criteria
- Identify numeric parameters that need tuning
- Document rationale for parameter choices

**Key milestone:** User stories that validate systems deliver the intended experience

---

### Level-by-Level Question Templates

Use these questions to guide product owners through each level. Adapt based on context.

#### **Level 1: Foundational Philosophy**

1. **"What problem does this product solve, and why must it exist?"** â€” Focus on user pain and transformation, not features (Mission)
2. **"What 3-5 core experiences or emotions should users feel?"** â€” These become your Design Pillars
3. **"For each pillar, what specific feeling are you creating?"** â€” Joy? Empowered? Calm? Confident? Be specific.
4. **"What principles would you never violate, even if it cost features or users?"** â€” Identify inviolable constraints
5. **"Who is this NOT for? What will this product NOT do?"** â€” Define boundaries through exclusion
6. **"If this product succeeds, how will users' lives be different in 6 months?"** â€” Validate long-term impact (North-star)

**Warning Signs for Design Pillars:**
- Too many pillars (>8): Dilutes focus, pick the core 3-5
- Feature-specific: "Combat system" is too narrow; "Empowered Action" is better
- Too generic: "Make users happy" applies to everything
- Implementation details: "React-based architecture" doesn't belong here

#### **Level 2: Stable Truths**

1. **"What design philosophy or framework guides your approach?"** â€” Identify existing paradigms or create new ones
2. **"What are you optimizing for, and what trade-offs will you accept?"** â€” Surface competing values
3. **"What patterns from other domains apply here?"** â€” Game design? Education? Social systems?
4. **"What existing approaches are you rejecting, and why?"** â€” Learn from what NOT to do
5. **"How do you define success for this product?"** â€” Metrics, user behaviors, outcomes

#### **Level 3: Interaction Architecture**

1. **"Walk me through a complete user journey from start to finish"** â€” Get concrete flow, not abstract description
2. **"What triggers each interaction, and what feedback does the user receive?"** â€” Map the complete loop
3. **"Are there different scales of interaction? Immediate? Session-level? Cross-session?"** â€” Identify temporal architecture
4. **"What happens when things fail or users skip steps?"** â€” Explore edge cases early
5. **"How do different systems coordinate to create coherent experiences?"** â€” Understand cross-system orchestration

#### **Level 4: Systems**

1. **"What are the major subsystems, and what is each responsible for?"** â€” Establish boundaries
2. **"What data does each system manage? What are the key entities?"** â€” Define information architecture
3. **"What rules govern state transitions and system behavior?"** â€” Extract business logic
4. **"How do systems interact? What do they expose to each other?"** â€” Map interfaces and dependencies
5. **"What values are calculated, and from what inputs?"** â€” Identify derived fields and formulas

#### **Level 5: User Stories**

1. **"As a user, what would you want to accomplish in the first 5 minutes? First day? First week?"** â€” Extract temporal user needs
2. **"For each feature, what observable behaviors would confirm it's working?"** â€” Define acceptance criteria
3. **"Which features are absolutely essential (MVP) vs. nice-to-have vs. future?"** â€” Establish priority
4. **"What are the complete user journeys from entry to exit?"** â€” Map end-to-end flows
5. **"How would you know if the system is delivering the intended experience?"** â€” Validate alignment with Level 1

#### **Level 5: Fine Tuning**

1. **"What timing values matter? Response delays? Animation durations?"** â€” Identify temporal parameters
2. **"What numeric thresholds determine state changes?"** â€” Find decision boundaries
3. **"What scaling factors affect calculations?"** â€” Identify growth curves and multipliers
4. **"What are the rationales for these specific numbers?"** â€” Document reasoning for future tuning
5. **"How might these values change based on testing or feedback?"** â€” Plan for iteration

---

### Warning Signs & Anti-Patterns

Watch for these common mistakes and redirect appropriately:

| Level | Anti-Pattern | Example | Redirect Question |
|-------|-------------|---------|-------------------|
| **L1** | Features instead of purpose | "Points system and badges" | "Why must this product exist? What transformation?" |
| **L1** | Implementation constraints in principles | "React and microservices" | "What philosophical principles guide the experience?" |
| **L1** | Vague emotional goals | "Users should feel good" | "Specific emotion for Design Pillar? Empowered? Calm? Accomplished?" |
| **L1** | Too many design pillars | "8 different core experiences" | "What are the 3-5 MOST important experiences that define this product?" |
| **L2** | Referencing system implementations | "Task System uses priority queue" | "What's the design philosophy about task management?" |
| **L2** | Including numeric parameters | "Tasks worth 100 points" | "What's the strategic approach to rewards?" |
| **L2** | Mixing strategy with interaction | "Celebration animation on completion" | "What's the stable truth about feedback?" |
| **L3** | Jumping to UI/UX implementation | "Button in top-right corner" | "What interaction is the user performing?" |
| **L3** | Referencing system logic | "Reward System formula from doc" | "What's the behavioral loop from user's perspective?" |
| **L3** | Skipping failure modes | Only describes happy paths | "What happens with abandonment? Missing data?" |
| **L4** | Actual values vs placeholders | "Tasks earn 100 points" | "Use placeholder like `[base_task_points]`" |
| **L4** | Referencing user stories | "As per user story #47..." | "What's the system rule independent of stories?" |
| **L4** | Writing code vs conceptual | Provides code snippets | "Describe the logic conceptually, not as code" |
| **L5** | Implementation in user stories | "TaskManager class updates database" | "Focus on user intent: 'save task, don't lose work'" |
| **L5** | Vague acceptance criteria | "It should work properly" | "What specific behaviors would confirm it's working?" |
| **L5** | Values without rationale | "Timeout = 30 seconds" | "Why 30 seconds? What's the reasoning?" |

---

### Validation Checklists

Use this matrix to verify each level is complete before descending:

| Validation Criterion | L1 | L2 | L3 | L4 | L5 |
|---------------------|----|----|----|----|-----|
| **Core Content Complete** | Mission & inviolable principles articulated | Design philosophies with justification | Complete user journeys documented | All subsystems with clear boundaries | Stories organized by priority/journey/system |
| **Proper Detail Level** | Emotional goals specific (not "feel good") | Strategy explained, not implementation | Behavioral flow, not UI details | Rules conceptual, not code | Observable acceptance criteria |
| **Reference Constraints** | No project docs referenced | No L3-5 referenced | No L4-5 referenced | No L5 referenced | Can reference all levels |
| **Numeric Values** | No numbers (except philosophical) | Placeholders only | Placeholders only | Placeholders only | Actual values with rationale |
| **Completeness Checks** | Anti-goals defined; North-star described | Trade-offs documented; Success criteria align with L1 | Failure modes explored; System coordination described | Data models defined; Dependencies mapped | Stories validate experience; Tuning approach documented |
| **Special Requirements** | No features/systems/implementation | External frameworks referenced if applicable | Verification criteria for implementers | State transitions specified | L5 Stories: As [user], I want [action], so [outcome] format |
| **Special Requirements** | â€” | â€” | â€” | â€” | L5 Fine Tuning: Parameters organized logically; References to source systems |

---

### Cross-Cutting Concerns Guide

Some themes span multiple levels. Here's where each aspect belongs:

| Concern | Level 1 (WHY) | Level 2 (Strategy) | Level 3 (Interaction) | Level 4 (Systems) | Level 5 (Implementation) |
|---------|---------------|--------------------|-----------------------|-------------------|--------------------------|
| **Accessibility** | Core principle ("All deserve equal access") | WCAG compliance, keyboard-first | Navigation patterns, feedback modalities | ARIA attributes, focus management | User story validation + timing |
| **Security & Privacy** | Inviolable principle ("User data is sacred") | Zero-trust, encryption-at-rest | Auth/authz interaction flows | Permission models, data isolation | Security stories + config parameters |
| **Internationalization** | Global accessibility mission | Translation approach, cultural adaptation | RTL support, date formats | Locale storage, translation keys | i18n stories + locale tuning |
| **Performance** | UX principle ("Respect users' time") | Perceived vs. actual speed, progressive enhancement | Optimistic updates, loading states | Caching strategies, lazy loading | Performance stories + timing parameters |

**Key principle:** The concern's **philosophy** lives at high levels, while **implementation details** cascade down to appropriate levels.

---

### Example Dialog Patterns

These examples show effective AI-user interactions during spec creation.

#### **Example 1: Extracting True "Why" (Level 1)**

**Problem:** User jumps to features ("task list and point system") instead of defining purpose.

**Solution progression:**
1. Challenge surface statement ("People need to get more done")
2. Identify gap in existing solutions ("They make people feel burned out")
3. Extract emotional goal ("Energized and in control, not drained")
4. Crystallize principle ("Sustainable productivity through energy awareness")
5. Define inviolable constraint ("Never add features that make users feel guilty")

**Key lesson:** Keep asking "why" until you reach emotional/philosophical foundation.

---

#### **Example 2: Defining Interaction Architecture (Level 3)**

**Problem:** User describes UI ("green checkmark appears") instead of behavioral pattern.

**Solution - Map complete interaction loop:**
- **Trigger:** User decides task is finished
- **Action:** Tap/click to mark complete
- **Reward:** Visual confirmation + points increase
- **Investment:** Points accumulate toward future rewards

**Result:** Hook Model loop documented at conceptual level, independent of visual design.

**Key lesson:** Guide users to describe behavioral loops, not visual implementations.

---

#### **Example 3: Redirecting Level Jumps**

**Problem:** User places system rule ("tasks earn points based on difficulty") in Level 1.

**Solution - Separate philosophy from implementation:**
- **Level 1 (Philosophy):** "Value meaningful effort over mere completion"
- **Level 4 (System Rule):** Points-per-difficulty calculation

**Key lesson:** Continuously enforce hierarchy; redirect implementation details to appropriate levels.

---

## Benefits

This framework provides:

- **Philosophical stability** â€” Core values don't change with implementation details
- **Implementation flexibility** â€” Completely refactor systems without changing principles
- **Clear decision boundaries** â€” Know where each type of decision belongs
- **Reduced cognitive load** â€” Each document has a clear scope and audience
- **Easier onboarding** â€” New team members can read from Level 1 downward
- **Safer AI assistance** â€” AI systems can understand and respect architectural constraints
- **Testable integrity** â€” Can automatically validate reference rules
